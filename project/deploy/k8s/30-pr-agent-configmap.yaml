apiVersion: v1
kind: ConfigMap
metadata:
  name: pr-agent-config
  namespace: llms
data:
  configuration.toml: |
    [config]
    model = "qwen3-coder-30b-local"
    fallback_models = ["qwen3-coder-30b-local"]
    custom_model_max_tokens = 8192
    ai_timeout=700 # Needed for R9 AI x370 cpu based ai
    [github]
    deployment_type = "app"

    # LiteLLM/OpenAI-style config â€“ we point at your local server
    [litellm_proxy]
    custom_llm_provider = "openai"
    api_base = "http://coder-30b-q4km-svc.llms.svc.cluster.local:8000"
    #api_key might be needed here
